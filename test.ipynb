{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sdf_utils import sap\n",
    "import time\n",
    "import random\n",
    "import deep_sdf\n",
    "from deep_sdf import mesh, metrics, lr_scheduling, plotting, utils, loss\n",
    "import deep_sdf.workspace as ws\n",
    "import json\n",
    "import os\n",
    "import reconstruct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec_with_default(specs, key, default):\n",
    "    try:\n",
    "        return specs[key]\n",
    "    except KeyError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = \"examples/torus/Run_w_con_loss_one_variable_usual\"\n",
    "specs = ws.load_experiment_specifications(experiment_directory)\n",
    "data_source = specs[\"DataSource\"]\n",
    "test_split_file = specs[\"TestSplit\"]\n",
    "with open(test_split_file, \"r\") as f:\n",
    "    test_split = json.load(f)\n",
    "eval_test_scene_num = get_spec_with_default(specs, \"EvalTestSceneNumber\", 10)\n",
    "eval_test_optimization_steps = get_spec_with_default(specs, \"EvalTestOptimizationSteps\", 1000)\n",
    "eval_grid_res = get_spec_with_default(specs, \"EvalGridResolution\", 256)\n",
    "torus_path = get_spec_with_default(specs, \"TorusPath\", \"/home/jakaria/torus_two_models_data/torus_two/obj_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (lin0): Linear(in_features=19, out_features=512, bias=True)\n",
       "  (lin1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin3): Linear(in_features=512, out_features=493, bias=True)\n",
       "  (lin4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin5): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin7): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (th): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        experiment_directory, ws.model_params_subdir, \"latest\" + \".pth\"\n",
    "    )\n",
    ")\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "decoder = decoder.module.cuda()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_time_start = time.time()\n",
    "test_err_sum = 0.\n",
    "chamfer_dists = []\n",
    "chamfer_dists_all = []\n",
    "test_loss_hists = []\n",
    "mesh_label_names = []\n",
    "test_latents = []\n",
    "sap_scores = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_filenames = deep_sdf.data.get_instance_filenames(data_source, test_split)\n",
    "labels = torch.load(data_source + \"/labels.pt\")\n",
    "eval_test_filenames = random.sample(eval_test_filenames, max(eval_test_scene_num, len(eval_test_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0848.npz...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing latent code for reconstruction of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_fname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m test_loss_hist, test_latent \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_test_optimization_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_sdf_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [emp_mean,emp_var],\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml2reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_loss_hist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(test_loss_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     31\u001b[0m     test_err_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m test_loss_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/INR/Deep3DComp/reconstruct.py:70\u001b[0m, in \u001b[0;36mreconstruct\u001b[0;34m(decoder, num_iterations, latent_size, test_sdf, stat, clamp_dist, num_samples, lr, l2reg, return_loss_hist)\u001b[0m\n\u001b[1;32m     66\u001b[0m latent_inputs \u001b[38;5;241m=\u001b[39m latent\u001b[38;5;241m.\u001b[39mexpand(num_samples, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([latent_inputs, xyz], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 70\u001b[0m pred_sdf \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# TODO: why is this needed?\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/inr_sdf/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/INR/Deep3DComp/networks/deep_sdf_decoder.py:104\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m     bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(layer))\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m bn(x)\n\u001b[0;32m--> 104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[1;32m    106\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_prob, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(test_fname).split(\".npz\")[0]\n",
    "    label = labels.get(save_name)\n",
    "    all_labels.append(label)\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, \"test_contrastive_one\", ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Optimizing latent code for reconstruction of {test_fname}...\")\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "    \n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "    print(f\"Reconstruction of {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    print(f\"Creating mesh for {test_fname}...\")\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        test_mesh = mesh.create_mesh(\n",
    "            decoder, \n",
    "            test_latent, \n",
    "            N=eval_grid_res, \n",
    "            max_batch=int(2 ** 18), \n",
    "            filename=os.path.join(path, f\"epoch={saved_model_epoch}\"),\n",
    "            return_trimesh=True,\n",
    "        )\n",
    "    print(f\"Mesh creation for {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    if test_mesh is not None:\n",
    "        gt_mesh_path = f\"{torus_path}/{save_name}.obj\"\n",
    "        cd, cd_all = metrics.compute_metric(gt_mesh=gt_mesh_path, gen_mesh=test_mesh, metric=\"chamfer\")\n",
    "        chamfer_dists.append(cd)\n",
    "        chamfer_dists_all.append(cd_all)\n",
    "\n",
    "    del test_sdf_samples, test_mesh\n",
    "\n",
    "# Calculate SAP scores\n",
    "sap_score = sap(factors=all_labels, codes=test_latents.detach().cpu().numpy(), continuous_factors=False, regression=False)\n",
    "\n",
    "if chamfer_dists:\n",
    "    mlm = torch.mean(torch.norm(torch.cat(test_latents, dim=0), dim=1))\n",
    "    fig = plotting.plot_train_stats(loss_hists=test_loss_hists, labels=mesh_label_names)\n",
    "    fig, percentiles = plotting.plot_dist_violin(np.concatenate(chamfer_dists_all, axis=0))\n",
    "    for p in [75, 90, 99]:\n",
    "        if p in percentiles:\n",
    "            print(f\"CD Percentile {p}th: {percentiles[p]}\")\n",
    "    \n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0248.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0248.npz took 9.346868991851807 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1540.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1540.npz took 8.992026090621948 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3601.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3601.npz took 9.030343532562256 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4653.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4653.npz took 9.06264328956604 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3755.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3755.npz took 9.099532842636108 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1700.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1700.npz took 9.147141695022583 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2759.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2759.npz took 9.197431325912476 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1221.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1221.npz took 9.225264072418213 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4824.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4824.npz took 9.241509437561035 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3175.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3175.npz took 9.275672674179077 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1029.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1029.npz took 9.299176931381226 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3555.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3555.npz took 9.305395603179932 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2118.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2118.npz took 9.339369773864746 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0848.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0848.npz took 9.344354391098022 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3768.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3768.npz took 9.387215852737427 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4717.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4717.npz took 9.380531072616577 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4619.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4619.npz took 9.412423133850098 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0796.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0796.npz took 9.40091872215271 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0818.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0818.npz took 9.432963371276855 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3446.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3446.npz took 9.464879274368286 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4825.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4825.npz took 9.468595504760742 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2728.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2728.npz took 9.483032941818237 seconds.\n"
     ]
    }
   ],
   "source": [
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(test_fname).split(\".npz\")[0]\n",
    "    label = labels.get(save_name)\n",
    "    all_labels.append(label[0])\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, \"test_contrastive_one\", ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Optimizing latent code for reconstruction of {test_fname}...\")\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "\n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "    print(f\"Reconstruction of {test_fname} took {time.time()-start} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_latents = torch.cat(test_latents)\n",
    "all_labels = np.array(all_labels)\n",
    "test_latents = test_latents.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SAP scores...\n",
      "latent size: (22, 16)\n",
      "all_labels size: (22, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Calculating SAP scores...\")\n",
    "print(f\"latent size: {test_latents.shape}\")\n",
    "print(f\"all_labels size: {all_labels.shape}\")\n",
    "sap_score = sap(factors=all_labels, codes=test_latents, continuous_factors=False, regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP scores: 0.045454545454545414\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAP scores (attribute vae): {sap_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP scores (contrastive one variable): 0.09090909090909094\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAP scores (contrastive one variable): {sap_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for each latent variable: [ 0.11417606  0.06719077  0.04534976  0.09525654 -0.02522508 -0.06407054\n",
      " -0.0300089   0.04920398  0.04075307  0.00277608  0.15100327 -0.00095985\n",
      " -0.077442   -0.03339227  0.07768717  0.01228157]\n",
      "Standard deviation for each latent variable: [0.6846151  0.18429531 0.12822926 0.1802207  0.14744131 0.15811083\n",
      " 0.16598548 0.21823612 0.16990103 0.26519656 0.16460398 0.24282835\n",
      " 0.2131904  0.13829003 0.20798773 0.15679179]\n"
     ]
    }
   ],
   "source": [
    "latent_mean = np.mean(test_latents, axis=0)\n",
    "latent_std = np.std(test_latents, axis=0)\n",
    "\n",
    "print(\"Mean for each latent variable:\", latent_mean)\n",
    "print(\"Standard deviation for each latent variable:\", latent_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each latent variable and display the plot\n",
    "for i in range(test_latents.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.hist(test_latents[:, i], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(f\"Distribution of Latent Variable {i}\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    # Show the plot inline in the notebook\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_sdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
