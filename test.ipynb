{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf_utils import sap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_time_start = time.time()\n",
    "test_err_sum = 0.\n",
    "chamfer_dists = []\n",
    "chamfer_dists_all = []\n",
    "test_loss_hists = []\n",
    "mesh_label_names = []\n",
    "test_latents = []\n",
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(sdf_dataset.npyfiles[index]).split(\".npz\")[0]\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, ws.tb_logs_dir, ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "    logging.debug(\"[Test eval] Total reconstruction time: {}\".format(time.time() - start))\n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        test_mesh = mesh.create_mesh(\n",
    "            decoder, \n",
    "            test_latent, \n",
    "            N=eval_grid_res, \n",
    "            max_batch=int(2 ** 18), \n",
    "            filename=os.path.join(path, f\"epoch={epoch}\"),\n",
    "            return_trimesh=True,\n",
    "        )\n",
    "    logging.debug(\"[Test eval] Total time to create test mesh: {}\".format(time.time() - start))\n",
    "\n",
    "    if test_mesh is not None:\n",
    "        gt_mesh_path = f\"{torus_path}/{save_name}.obj\"\n",
    "        cd, cd_all = metrics.compute_metric(gt_mesh=gt_mesh_path, gen_mesh=test_mesh, metric=\"chamfer\")\n",
    "        chamfer_dists.append(cd)\n",
    "        chamfer_dists_all.append(cd_all)\n",
    "\n",
    "    del test_sdf_samples, test_mesh\n",
    "\n",
    "if chamfer_dists:\n",
    "    logging.debug(f\"Test Chamfer distance mean: {sum(chamfer_dists)/len(chamfer_dists)} from {chamfer_dists}.\")            \n",
    "    summary_writer.add_scalar(\"Mean Chamfer Dist/test\", sum(chamfer_dists)/len(chamfer_dists), epoch)\n",
    "    summary_writer.add_scalar(\"Loss/test\", test_err_sum/len(eval_test_filenames), epoch)\n",
    "    mlm = torch.mean(torch.norm(torch.cat(test_latents, dim=0), dim=1))\n",
    "    summary_writer.add_scalar(\"Mean Latent Magnitude/test\", mlm, global_step=epoch)\n",
    "    fig = plotting.plot_train_stats(loss_hists=test_loss_hists, labels=mesh_label_names)\n",
    "    summary_writer.add_figure(\"Loss/test optimization curves\", fig, epoch)\n",
    "    fig, percentiles = plotting.plot_dist_violin(np.concatenate(chamfer_dists_all, axis=0))\n",
    "    summary_writer.add_figure(\"CD Percentiles/test dists\", fig, global_step=epoch)\n",
    "    for p in [75, 90, 99]:\n",
    "        if p in percentiles:\n",
    "            summary_writer.add_scalar(f\"CD Percentiles/test {p}th\", percentiles[p], global_step=epoch)\n",
    "summary_writer.add_scalar(\"Time/test eval per shape (sec)\", (time.time()-eval_test_time_start)/len(eval_test_filenames), epoch)\n",
    "# End of eval test.\n",
    "\n",
    "summary_writer.add_scalar(\"Time/epoch (min)\", (time.time()-epoch_time_start)/60, epoch)\n",
    "summary_writer.flush() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_sdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
