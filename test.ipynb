{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sdf_utils import sap\n",
    "import time\n",
    "import random\n",
    "import deep_sdf\n",
    "from deep_sdf import mesh, metrics, lr_scheduling, plotting, utils, loss\n",
    "import deep_sdf.workspace as ws\n",
    "import json\n",
    "import os\n",
    "import reconstruct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec_with_default(specs, key, default):\n",
    "    try:\n",
    "        return specs[key]\n",
    "    except KeyError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = \"examples/torus\"\n",
    "specs = ws.load_experiment_specifications(experiment_directory)\n",
    "data_source = specs[\"DataSource\"]\n",
    "test_split_file = specs[\"TestSplit\"]\n",
    "with open(test_split_file, \"r\") as f:\n",
    "    test_split = json.load(f)\n",
    "eval_test_scene_num = get_spec_with_default(specs, \"EvalTestSceneNumber\", 10)\n",
    "eval_test_optimization_steps = get_spec_with_default(specs, \"EvalTestOptimizationSteps\", 1000)\n",
    "eval_grid_res = get_spec_with_default(specs, \"EvalGridResolution\", 256)\n",
    "torus_path = get_spec_with_default(specs, \"TorusPath\", \"/home/jakaria//torus_two_models_data/torus_two/obj_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        experiment_directory, ws.model_params_subdir, \"latest\" + \".pth\"\n",
    "    )\n",
    ")\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "decoder = decoder.module.cuda()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_time_start = time.time()\n",
    "test_err_sum = 0.\n",
    "chamfer_dists = []\n",
    "chamfer_dists_all = []\n",
    "test_loss_hists = []\n",
    "mesh_label_names = []\n",
    "test_latents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_filenames = deep_sdf.data.get_instance_filenames(data_source, test_split)\n",
    "eval_test_filenames = random.sample(eval_test_filenames, min(eval_test_scene_num, len(eval_test_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(test_fname).split(\".npz\")[0]\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, \"test_contrastive_one\", ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Reconstructing {test_fname}...\")\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "    \n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "    print(f\"Reconstruction of {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    print(f\"Creating mesh for {test_fname}...\")\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        test_mesh = mesh.create_mesh(\n",
    "            decoder, \n",
    "            test_latent, \n",
    "            N=eval_grid_res, \n",
    "            max_batch=int(2 ** 18), \n",
    "            filename=os.path.join(path, f\"epoch={epoch}\"),\n",
    "            return_trimesh=True,\n",
    "        )\n",
    "    print(f\"Mesh creation for {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    if test_mesh is not None:\n",
    "        gt_mesh_path = f\"{torus_path}/{save_name}.obj\"\n",
    "        cd, cd_all = metrics.compute_metric(gt_mesh=gt_mesh_path, gen_mesh=test_mesh, metric=\"chamfer\")\n",
    "        chamfer_dists.append(cd)\n",
    "        chamfer_dists_all.append(cd_all)\n",
    "\n",
    "    del test_sdf_samples, test_mesh\n",
    "\n",
    "if chamfer_dists:\n",
    "    mlm = torch.mean(torch.norm(torch.cat(test_latents, dim=0), dim=1))\n",
    "    fig = plotting.plot_train_stats(loss_hists=test_loss_hists, labels=mesh_label_names)\n",
    "    fig, percentiles = plotting.plot_dist_violin(np.concatenate(chamfer_dists_all, axis=0))\n",
    "    for p in [75, 90, 99]:\n",
    "        if p in percentiles:\n",
    "            print(f\"CD Percentile {p}th: {percentiles[p]}\")\n",
    "    \n",
    "    plt.show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_sdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
