{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sdf_utils import sap\n",
    "import time\n",
    "import random\n",
    "import deep_sdf\n",
    "from deep_sdf import mesh, metrics, lr_scheduling, plotting, utils, loss\n",
    "import deep_sdf.workspace as ws\n",
    "import json\n",
    "import os\n",
    "import reconstruct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec_with_default(specs, key, default):\n",
    "    try:\n",
    "        return specs[key]\n",
    "    except KeyError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = \"examples/torus\"\n",
    "specs = ws.load_experiment_specifications(experiment_directory)\n",
    "data_source = specs[\"DataSource\"]\n",
    "test_split_file = specs[\"TestSplit\"]\n",
    "with open(test_split_file, \"r\") as f:\n",
    "    test_split = json.load(f)\n",
    "eval_test_scene_num = get_spec_with_default(specs, \"EvalTestSceneNumber\", 10)\n",
    "eval_test_optimization_steps = get_spec_with_default(specs, \"EvalTestOptimizationSteps\", 1000)\n",
    "eval_grid_res = get_spec_with_default(specs, \"EvalGridResolution\", 256)\n",
    "torus_path = get_spec_with_default(specs, \"TorusPath\", \"/home/jakaria//torus_two_models_data/torus_two/obj_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (lin0): Linear(in_features=19, out_features=512, bias=True)\n",
       "  (lin1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin3): Linear(in_features=512, out_features=493, bias=True)\n",
       "  (lin4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin5): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin7): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (th): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "saved_model_state = torch.load(\n",
    "    os.path.join(\n",
    "        experiment_directory, ws.model_params_subdir, \"latest\" + \".pth\"\n",
    "    )\n",
    ")\n",
    "saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "decoder = decoder.module.cuda()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_time_start = time.time()\n",
    "test_err_sum = 0.\n",
    "chamfer_dists = []\n",
    "chamfer_dists_all = []\n",
    "test_loss_hists = []\n",
    "mesh_label_names = []\n",
    "test_latents = []\n",
    "sap_scores = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test_filenames = deep_sdf.data.get_instance_filenames(data_source, test_split)\n",
    "labels = torch.load(data_source + \"/labels.pt\")\n",
    "eval_test_filenames = random.sample(eval_test_filenames, max(eval_test_scene_num, len(eval_test_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(test_fname).split(\".npz\")[0]\n",
    "    label = labels.get(save_name)\n",
    "    all_labels.append(label)\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, \"test_contrastive_one\", ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Optimizing latent code for reconstruction of {test_fname}...\")\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "    \n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "    print(f\"Reconstruction of {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    print(f\"Creating mesh for {test_fname}...\")\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        test_mesh = mesh.create_mesh(\n",
    "            decoder, \n",
    "            test_latent, \n",
    "            N=eval_grid_res, \n",
    "            max_batch=int(2 ** 18), \n",
    "            filename=os.path.join(path, f\"epoch={saved_model_epoch}\"),\n",
    "            return_trimesh=True,\n",
    "        )\n",
    "    print(f\"Mesh creation for {test_fname} took {time.time()-start} seconds.\")\n",
    "\n",
    "    if test_mesh is not None:\n",
    "        gt_mesh_path = f\"{torus_path}/{save_name}.obj\"\n",
    "        cd, cd_all = metrics.compute_metric(gt_mesh=gt_mesh_path, gen_mesh=test_mesh, metric=\"chamfer\")\n",
    "        chamfer_dists.append(cd)\n",
    "        chamfer_dists_all.append(cd_all)\n",
    "\n",
    "    del test_sdf_samples, test_mesh\n",
    "\n",
    "# Calculate SAP scores\n",
    "sap_score = sap(factors=all_labels, codes=test_latents.detach().cpu().numpy(), continuous_factors=False, regression=False)\n",
    "\n",
    "if chamfer_dists:\n",
    "    mlm = torch.mean(torch.norm(torch.cat(test_latents, dim=0), dim=1))\n",
    "    fig = plotting.plot_train_stats(loss_hists=test_loss_hists, labels=mesh_label_names)\n",
    "    fig, percentiles = plotting.plot_dist_violin(np.concatenate(chamfer_dists_all, axis=0))\n",
    "    for p in [75, 90, 99]:\n",
    "        if p in percentiles:\n",
    "            print(f\"CD Percentile {p}th: {percentiles[p]}\")\n",
    "    \n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0848.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0848.npz took 9.433819770812988 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1221.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1221.npz took 9.062754154205322 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1700.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1700.npz took 9.087751388549805 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1029.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1029.npz took 9.154362916946411 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0818.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0818.npz took 9.199928522109985 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0248.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0248.npz took 9.222569227218628 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3175.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3175.npz took 9.244002342224121 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1540.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_1540.npz took 9.287998676300049 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2728.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2728.npz took 9.319733142852783 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4825.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4825.npz took 9.342746019363403 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3555.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3555.npz took 9.366109132766724 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4717.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4717.npz took 9.375546216964722 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0796.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_0796.npz took 9.396687507629395 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2118.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2118.npz took 9.430191040039062 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4653.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4653.npz took 9.445649862289429 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4619.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4619.npz took 9.457199096679688 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2759.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_2759.npz took 9.480908870697021 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3755.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3755.npz took 9.489624261856079 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3768.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3768.npz took 9.488159656524658 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4824.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_4824.npz took 9.478824853897095 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3601.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3601.npz took 9.510951042175293 seconds.\n",
      "Optimizing latent code for reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3446.npz...\n",
      "Reconstruction of /home/jakaria/torus_bump_5000_two_scale_binary_bump_variable_noise_fixed_angle/sdf_data/SdfSamples/obj_files/torus_bump_3446.npz took 9.52835488319397 seconds.\n"
     ]
    }
   ],
   "source": [
    "for test_fname in eval_test_filenames:\n",
    "    save_name = os.path.basename(test_fname).split(\".npz\")[0]\n",
    "    label = labels.get(save_name)\n",
    "    all_labels.append(label[0])\n",
    "    mesh_label_names.append(save_name)\n",
    "    path = os.path.join(experiment_directory, \"test_contrastive_one\", ws.tb_logs_test_reconstructions, save_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    test_fpath = os.path.join(data_source, ws.sdf_samples_subdir, test_fname)\n",
    "    test_sdf_samples = deep_sdf.data.read_sdf_samples_into_ram(test_fpath)\n",
    "    test_sdf_samples[0] = test_sdf_samples[0][torch.randperm(test_sdf_samples[0].shape[0])]\n",
    "    test_sdf_samples[1] = test_sdf_samples[1][torch.randperm(test_sdf_samples[1].shape[0])]\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Optimizing latent code for reconstruction of {test_fname}...\")\n",
    "    test_loss_hist, test_latent = reconstruct.reconstruct(\n",
    "        decoder,\n",
    "        int(eval_test_optimization_steps),\n",
    "        latent_size,\n",
    "        test_sdf_samples,\n",
    "        0.01,  # [emp_mean,emp_var],\n",
    "        0.1,\n",
    "        num_samples=8000,\n",
    "        lr=5e-3,\n",
    "        l2reg=True,\n",
    "        return_loss_hist=True\n",
    "    )\n",
    "\n",
    "    if not np.isnan(test_loss_hist[-1]):\n",
    "        test_err_sum += test_loss_hist[-1]\n",
    "    test_loss_hists.append(test_loss_hist)\n",
    "    test_latents.append(test_latent)\n",
    "    print(f\"Reconstruction of {test_fname} took {time.time()-start} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_latents = torch.cat(test_latents)\n",
    "all_labels = np.array(all_labels)\n",
    "test_latents = test_latents.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SAP scores...\n",
      "latent size: (22, 16)\n",
      "all_labels size: (22, 1)\n",
      "SAP scores: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Calculating SAP scores...\")\n",
    "print(f\"latent size: {test_latents.shape}\")\n",
    "print(f\"all_labels size: {all_labels.shape}\")\n",
    "sap_score = sap(factors=all_labels, codes=test_latents, continuous_factors=False, regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP scores: 0.045454545454545414\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAP scores: {sap_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_sdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
